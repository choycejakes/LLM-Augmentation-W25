{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will cover the very basics of LangChain. This includes chains and templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import necessary libraries, and use `dotenv` to load our OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamee_fy\\AppData\\Local\\Temp\\ipykernel_20512\\1543617194.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_key=api_key)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In every chat, LLMs are typically first introduced to a \"system message,\" instructing the LLM on how to interpret the conversation. There is also a \"human\" or \"user\" message which is simply what the user sends to the LLM. An \"assistant\" or \"AI\" message is associated with the messages that the LLM itself writes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamee_fy\\AppData\\Local\\Temp\\ipykernel_20512\\2497210350.py:6: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(messages=messages, temperature=0.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(1000, 5)\n",
      "y = np.random.randint(0, 2, 1000)\n",
      "\n",
      "# Split data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "# Build a simple neural network model\n",
      "model = Sequential()\n",
      "model.add(Dense(10, input_dim=5, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist.\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data. Only return the script.\")\n",
    "]\n",
    "\n",
    "response = llm(messages=messages, temperature=0.6)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the \"temperature\" parameter. Temperature is a parameter that refers to the probability with which the LLM's underlying next token predictor picks out a next token that is not the highest probability token. You can consider to it a proxy for \"creativity.\" Higher temperature -> more randomness -> more \"creativity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent prompts using \"prompt templates,\" which allow us to dynamically plug things into prompts. The `PromptTemplate` class is simply LangChain's object interface with prompts. Chains allow us to link prompts together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Explain {topic} in one sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gamee_fy\\AppData\\Local\\Temp\\ipykernel_20512\\1723417862.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(prompt=prompt, llm=llm)\n",
      "C:\\Users\\gamee_fy\\AppData\\Local\\Temp\\ipykernel_20512\\1723417862.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(topic=\"atitude\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Attitude refers to a person's feelings, beliefs, and behaviors towards a particular situation, person, or thing.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "chain.run(topic=\"atitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Potato is a starchy tuber vegetable that is a staple food in many cultures around the world.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_topic_desc\"],\n",
    "    template=\"\"\"\n",
    "    You are a:\n",
    "    {ml_topic_desc}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "chain.run(topic = \"potato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the first chain are passed in to the second chain as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAn autoencoder is a type of artificial neural network that learns to reconstruct input data, typically used for dimensionality reduction and feature learning.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThis type of neural network is commonly used in unsupervised learning tasks such as image and text data compression, anomaly detection, and denoising. Autoencoders consist of an encoder network that compresses the input data into a lower-dimensional representation, and a decoder network that reconstructs the original input from this representation. By training the autoencoder to minimize the reconstruction error, it learns to capture the most important features of the input data in the encoded representation. This can be useful for tasks such as data visualization, pretraining for other machine learning models, and generating new data samples.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "This type of neural network is commonly used in unsupervised learning tasks such as image and text data compression, anomaly detection, and denoising. Autoencoders consist of an encoder network that compresses the input data into a lower-dimensional representation, and a decoder network that reconstructs the original input from this representation. By training the autoencoder to minimize the reconstruction error, it learns to capture the most important features of the input data in the encoded representation. This can be useful for tasks such as data visualization, pretraining for other machine learning models, and generating new data samples.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "blog_post = overall_chain.run(input=\"autoencoder\")\n",
    "print(blog_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
